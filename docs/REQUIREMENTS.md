REQUIREMENTS â€“ Podman & VM 389-DS Environments

0) Scope & Goals

Provide two reproducible environments for 389-DS (containers on macOS Podman VM + RHEL VMs):
	â€¢	Development (DEV) â€“ persistent, longer-lived, restartable
	â€¢	Integration Testing (INT) â€“ ephemeral, no persistence, never restarted once seeded
	â€¢	VMs â€“ standard RHDS/389-ds-base on RHEL, must use same Ansible code

â¸»

1) Environment Matrix

Dimension	DEV (persistent)	INT (ephemeral)	VMs
Storage	Bind mounts (config/db/logs/certs)	Tmpfs/anon volumes (no bind mounts)	Local FS under /etc/dirsrv, /var/lib/dirsrv
Lifecycle	Start/stop/restart allowed	No restarts allowed; full teardown if needed	Start/stop/restart allowed (systemd)
Data seeding	Optional; incremental	Deterministic, clean every run	Deterministic
Image pinning	Tag-based (for iteration)	Immutable digest	Installed RPMs
Logging	Persist on host	Export artifacts before teardown	Local logs, copy summaries
DNS policy	Service names only	Service names only	FQDNs only


â¸»

2) Naming & Addressing
	â€¢	Containers: always use Compose service names (ds-s1, ds-s2, â€¦).
	â€¢	VMs: always use FQDN (e.g., rhds-a1.example.com).
	â€¢	Variable: dirsrv_advertised_hostname_final = the only name ever used in agreements or LDAP URLs.

Resolution rule (priority order):
	1.	dirsrv_advertised_hostname if defined
	2.	If dirsrv_target_type == container â†’ inventory_hostname (service name)
	3.	Else â†’ ansible_fqdn | default(inventory_hostname)

ðŸš« No IP literals. No mixing service names and FQDNs.

â¸»

3) Storage Layout

DEV
	â€¢	Persist all instance paths: /etc/dirsrv/..., /var/lib/dirsrv/..., /var/log/dirsrv/..., /etc/dirsrv/.../certs, /data/db.
	â€¢	Bind mounts live under .ansible/containers/<svc>/....

INT
	â€¢	Tmpfs/anon volumes only.
	â€¢	Recommended tmpfs:
	â€¢	/var/lib/dirsrv/...: size=1G
	â€¢	/var/log/dirsrv/...: size=128M
	â€¢	Any artifact needed must be copied out before teardown.

â¸»

4) Container Lifecycle Contracts
	â€¢	DEV: restarts allowed.
	â€¢	INT: restarts forbidden after seeding begins; if restart required, tear down and rebuild.
	â€¢	Enforced by role var:

dirsrv_no_restart: "{{ env_type == 'int' }}"


	â€¢	VMs: restarts allowed (systemd handlers).

â¸»

5) Deterministic Seeding (INT & VMs)
	â€¢	Start from clean slate.
	â€¢	Seed LDIF, schema, and indexes via idempotent tasks.
	â€¢	Sequence:
	1.	Base suffix creation
	2.	Required indexes/schema changes
	3.	Test entries load
	â€¢	Fail fast on divergence.

â¸»

6) Replication Setup
	â€¢	Agreements use dirsrv_advertised_hostname_final only.
	â€¢	Replica ID policy:
	â€¢	Suppliers get fixed IDs (1..N).
	â€¢	Consumers use 65535.
	â€¢	Verification:
	â€¢	Agreement present in dsconf list
	â€¢	Monitor reports green
	â€¢	RUV present, change count increasing

â¸»

7) Readiness & Preflight Gates

Sequence
	1.	DNS resolution (getent hosts {{ peer }})
	2.	TCP handshake (nc -vz {{ peer }} 389/636)
	3.	Base search over TCP LDAP (ldapsearch -x -H ldap://{{ peer }}:389)

LDAPI socket
	â€¢	Containers: /data/run/slapd-localhost.socket
	â€¢	VMs: /run/slapd-localhost.socket

â¸»

8) Observability & Artifacts
	â€¢	Logs: errors, access, audit.
	â€¢	Replication status: agreements, RUV per suffix.
	â€¢	namingContexts, listener sockets, Ansible timings, sanitized vars snapshot.

DEV: logs persist in bind mounts.
INT: export all artifacts to .ansible/artifacts/<run-id>/... before teardown.
VMs: leave logs on host; copy summaries.

â¸»

9) Security & Secrets
	â€¢	No secrets in git.
	â€¢	Provide via .env, Podman secrets, or Ansible vault.
	â€¢	Required:
	â€¢	DS_DM_PASSWORD
	â€¢	Any test bind DN passwords

â¸»

10) Image & Packages
	â€¢	DEV: pin to stable tag.
	â€¢	INT: pin by immutable digest (quay.io/389ds/dirsrv@sha256:...).
	â€¢	VMs: install RHDS/389-ds-base via RPM.

â¸»

11) Time & Sync
	â€¢	Max clock skew: â‰¤ 2s across nodes.
	â€¢	NTP must be enabled on Podman VM and VMs.

â¸»

12) Firewalld & SELinux (VMs only)
	â€¢	Open ports 389, 636.
	â€¢	Verify SELinux contexts/booleans for RHDS defaults.

â¸»

13) Timeouts (defaults)
	â€¢	LDAPI readiness (local): â‰¤ 20s
	â€¢	TCP readiness: â‰¤ 15s per peer
	â€¢	Initial replication init per agreement: â‰¤ 120s
	â€¢	Mesh convergence (4-node): â‰¤ 4m
	â€¢	Entire INT job: â‰¤ 10m

â¸»

14) Acceptance Criteria
	â€¢	Same Ansible role works for containers and VMs; only inventory/group vars differ.
	â€¢	Agreements always use canonical advertised hostname.
	â€¢	INT fails if:
	â€¢	restart occurs,
	â€¢	preflight gates fail, or
	â€¢	convergence exceeds SLA.
	â€¢	Artifacts are exported (INT) or persisted (DEV/VM).

â¸»

15) Non-Goals
	â€¢	TLS/PKI lifecycle (CSR/renewal) â€“ separate doc.
	â€¢	Multi-host Podman networking.
	â€¢	Reverse proxy/ingress design.

â¸»

16) Open Questions
	â€¢	Do we require TLS in INT runs, or only plaintext?
	â€¢	For INT: prefer tmpfs (fast, ephemeral) or anon volumes (less memory)?
	â€¢	Max acceptable convergence time in larger topologies (e.g., 30-node mesh)?

â¸»